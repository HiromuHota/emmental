# Meta information configuration
meta_config:
    seed: 0  # random seed for the model and learning
    verbose: True # whether to print the log information
    device: 0 # -1 for cpu or gpu id (e.g., 0 for cuda:0)

# Learning configuration
learner_config:
    fp16: False # whether to use half precision
    model_path: # the path to pretrained model
    n_epochs: 1
    train_split: train # accept str or list of strs
    valid_split: valid # accept str or list of strs
    test_split: test
    ignore_index: -100
    optimizer_config:
        optimizer: sgd # [sgd, adam]
        lr: 0.001
        l2: 0.0
        grad_clip: 1.0
        sgd_config:
            momentum: 0.9
        adam_config:
            betas: !!python/tuple [0.9, 0.999]
    lr_scheduler_config:
        lr_scheduler: linear # [linear, exponential, reduce_on_plateau]
        warmup_steps: 0
        warmup_unit: batch # [epoch, batch]
        min_lr: 0.0
        linear_config:
            min_lr: 0.0
        exponential_config:
            gamma: 0.9
        plateau_config:
            factor: 0.5
            patience: 10
            threshold: 0.0001
    task_scheduler: round_robin # [sequential, round_robin]

# Logging configuration
logging_config:
    counter_unit: batch # [epoch, batch]
    evaluation_freq: 2
    writer_config:
        writer: tensorboard # [json, tensorboard]
        verbose: True
    checkpointing: True
    checkpointer_config:
        checkpoint_path:
        checkpoint_freq: 1
        checkpoint_metric: model/train/all/loss
        checkpoint_metric_mode: max # [min, max]
        checkpoint_runway: 0

